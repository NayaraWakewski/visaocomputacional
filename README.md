Projeto de Vis√£o Computacional do Curso de Data Science da Infinity School

![texto alt](https://cdn.eadplataforma.app/client/infinityschool/upload/others/e993f6d822d15efdb3585d1b733e4020.png)


# Objetivo

O projeto visa construir uma rede Neural convolucional utilizando a biblioteca YOLO, para detec√ß√£o de imagens.

## ‚öôÔ∏è Instalando as Bibliotecas necess√°rias.

**Importando as Bibliotecas**: Nesta etapa, importamos as bibliotecas necess√°rias para execu√ß√£o do Projeto. Trabalharemos com: 

**pandas as pd:** Para manipula√ß√£o e an√°lise de dados tabulares.

**import cv2** Importando a biblioteca OpenCV para processamento de imagens em Python


## üöÄ Come√ßando - PIPELINE.

Nesta primeira parte do projeto, realizamos o inicio de um pipeline de objetos usando o modelo YOLO com OpenCV em Python.
Depois de carregar o modelo, as classes e a imagem de exemplo, voc√™ pode prosseguir com a detec√ß√£o de objetos na imagem de exemplo usando o modelo YOLO.

-Carrega o modelo YOLO (You Only Look Once) com os arquivos de configura√ß√£o 'yolov3.cfg' e os pesos 'yolov3.weights' usando a fun√ß√£o cv2.dnn.readNetFromDarknet.

-Carrega as classes reconhecidas pelo modelo YOLO a partir do arquivo 'coco.names' e as armazena em uma lista chamada classes.

-Define cores aleat√≥rias para cada classe e as armazena em uma matriz colors usando np.random.uniform.

-Carrega uma imagem de exemplo chamada 'exemplo.jpg' usando a fun√ß√£o cv2.imread.




## üöÄ CRIANDO O BLOB.

Um "blob" √© essencialmente uma matriz multidimensional que cont√©m os valores de pixel normalizados da imagem, juntamente com informa√ß√µes adicionais, como dimens√µes, canais e outras configura√ß√µes espec√≠ficas da rede neural.

```python
# Obter as dimens√µes da imagem
height, width, _ = image.shape

# Construir um blob a partir da imagem para o modelo YOLO
blob = cv2.dnn.blobFromImage(image, 1/255, (416, 416), swapRB=True, crop=False)
```

## üöÄ PREPARANDO O MODELO YOLO


Neste trecho de c√≥digo, o seguinte est√° acontecendo:

As camadas de sa√≠da do modelo YOLO s√£o definidas. Originalmente, parece que havia uma linha comentada #output_layers_names = net.getUnconnectedOutLayersNames(), que foi substitu√≠da por output_names = net.getUnconnectedOutLayersNames(). Isso cria uma lista output_names contendo os nomes das camadas de sa√≠da.

Em seguida, as camadas de sa√≠da s√£o obtidas a partir do modelo usando net.getLayer(name) para cada nome de camada em output_names. Isso cria uma lista de objetos de camada do OpenCV.

Os nomes das camadas de sa√≠da s√£o extra√≠dos desses objetos de camada e armazenados em output_layers.

O c√≥digo define o blob de entrada da rede neural usando net.setInput(blob). Presumivelmente, o objeto blob foi criado anteriormente a partir da imagem de exemplo usando a fun√ß√£o cv2.dnn.blobFromImage.

O modelo YOLO √© executado na imagem de exemplo, passando o blob pela rede neural, usando net.forward(output_layers). Isso produz uma lista de sa√≠das das camadas de sa√≠da do modelo.

As listas class_ids, confidences, e boxes s√£o inicializadas para armazenar informa√ß√µes sobre detec√ß√µes de objetos. Estas listas ser√£o preenchidas com informa√ß√µes sobre as detec√ß√µes de objetos na imagem ap√≥s a execu√ß√£o do modelo YOLO.

Este trecho do c√≥digo prepara o modelo YOLO para a detec√ß√£o de objetos na imagem de exemplo e configura as estruturas de dados necess√°rias para armazenar as informa√ß√µes sobre as detec√ß√µes.


## üöÄ PROCESSANDO AS SA√çDAS

Este trecho de c√≥digo √© respons√°vel pelo processamento das sa√≠das da rede neural YOLO, supress√£o n√£o m√°xima (NMS) para eliminar detec√ß√µes redundantes e desenho dos ret√¢ngulos delimitadores nas imagens de detec√ß√£o. Aqui est√° o que cada parte do c√≥digo faz:

Processar as sa√≠das da rede neural:

O c√≥digo itera sobre as sa√≠das da rede neural (outputs), que cont√™m informa√ß√µes sobre poss√≠veis detec√ß√µes de objetos na imagem.

Para cada detec√ß√£o em cada sa√≠da, s√£o extra√≠dos os escores de confian√ßa para todas as classes e a classe com a maior pontua√ß√£o (class_id) √© determinada.

Se a confian√ßa (confidence) para a detec√ß√£o for maior que 0,5, isso indica que a detec√ß√£o √© significativa, e suas informa√ß√µes s√£o extra√≠das, incluindo coordenadas, largura e altura do ret√¢ngulo delimitador.

As informa√ß√µes da detec√ß√£o (classe, confian√ßa e caixa delimitadora) s√£o armazenadas nas listas class_ids, confidences e boxes, respectivamente.

Aplicar a supress√£o n√£o m√°xima (NMS):

A supress√£o n√£o m√°xima √© uma t√©cnica usada para eliminar detec√ß√µes redundantes. O c√≥digo utiliza a fun√ß√£o cv2.dnn.NMSBoxes para calcular as caixas delimitadoras finais ap√≥s a aplica√ß√£o do NMS. As caixas, confian√ßas e um limiar (score_threshold e nms_threshold) s√£o fornecidos como entrada.
Desenhar os ret√¢ngulos delimitadores e exibir as classes nas detec√ß√µes:

Para cada caixa delimitadora resultante ap√≥s a aplica√ß√£o do NMS, o c√≥digo desenha um ret√¢ngulo na imagem original usando cv2.rectangle e exibe a classe e a confian√ßa acima do ret√¢ngulo usando cv2.putText.
Exibir a imagem com as detec√ß√µes:

Finalmente, o c√≥digo exibe a imagem com as detec√ß√µes na janela "Object Detection" usando cv2.imshow. O usu√°rio pode visualizar as detec√ß√µes e aguardar at√© que uma tecla seja pressionada (cv2.waitKey(0)) antes de fechar a janela (cv2.destroyAllWindows()).
Este c√≥digo realiza a detec√ß√£o de objetos na imagem de exemplo usando o modelo YOLO e exibe a imagem com os ret√¢ngulos delimitadores e as classes identificadas.


   
### üõ†Ô∏è Ferramentas

> **Para elabora√ß√£o do Projeto utilizamos as seguintes ferramentas:**

- **Visual Studio Code** - utilizado para organizar as etapas do projeto, e criar os notebooks Jupyter.
- **Github** - Plataforma de hospedagem de c√≥digo, que utilizamos para subir o projeto.



## ‚öôÔ∏è Para detec√ß√£o da imagem direto da Webcam, esse seria o c√≥digo:


- **Importando Bibliotecas**

```python
#Importando Bibliotecas
import cv2
import numpy as np
# Carregar os arquivos do modelo YOLO (os arquivos que n√≥s baixamos)
net = cv2.dnn.readNetFromDarknet('yolov3.cfg', 'yolov3.weights')
# Carregar as classes - e transformando em uma lista
classes = []
f = open('coco.names', 'r')
lines = f.readlines()
f.close()

for line in lines:
    classes.append(line.strip())
# Configurar cores aleat√≥rias para cada classe
colors = np.random.uniform(0, 255, size=(len(classes), 3))

# Inicializar a captura de v√≠deo da webcam
cap = cv2.VideoCapture(0)

while True:
    # Ler o pr√≥ximo quadro da captura de v√≠deo
    ret, frame = cap.read()

    # Verificar se a captura de v√≠deo foi bem-sucedida
    if not ret:
        break

    # Obter as dimens√µes do quadro
    height, width, _ = frame.shape

    # Construir um blob a partir do quadro para o modelo YOLO
    blob = cv2.dnn.blobFromImage(frame, 1/255, (416, 416), swapRB=True, crop=False)

    # Definir as camadas de sa√≠da
    output_names = net.getUnconnectedOutLayersNames()
    output_layers = [net.getLayer(name) for name in output_names]
    output_layers = [layer.name for layer in output_layers]

    # Passar o blob pela rede neural
    net.setInput(blob)
    outputs = net.forward(output_layers)

    # Configurar as listas de detec√ß√£o
    class_ids = []
    confidences = []
    boxes = []

    # Processar as sa√≠das da rede neural
    for output in outputs:
        for detection in output:
            scores = detection[5:]
            class_id = np.argmax(scores)
            confidence = scores[class_id]

            if confidence > 0.5:
                # Obter as coordenadas do objeto detectado
                center_x = int(detection[0] * width)
                center_y = int(detection[1] * height)
                w = int(detection[2] * width)
                h = int(detection[3] * height)

                # Calcular os cantos do ret√¢ngulo delimitador
                x = int(center_x - w / 2)
                y = int(center_y - h / 2)

                # Adicionar as informa√ß√µes √† lista de detec√ß√£o
                class_ids.append(class_id)
                confidences.append(float(confidence))
                boxes.append([x, y, w, h])

    # Aplicar a supress√£o n√£o m√°xima para eliminar detec√ß√µes redundantes
    indices = cv2.dnn.NMSBoxes(boxes, confidences, score_threshold=0.5, nms_threshold=0.4)

    # Desenhar os ret√¢ngulos delimitadores e exibir as classes nas detec√ß√µes
    for i in indices:
        box = boxes[i]
        x, y, w, h = box
        label = f'{classes[class_ids[i]]}: {confidences[i]:.2f}'
        color = colors[class_ids[i]]

        cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)
        cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

    # Exibir o quadro com as detec√ß√µes
    cv2.imshow('Object Detection', frame)

    # Parar o loop se a tecla 'q' for pressionada
    if cv2.waitKey(1) == ord('q'):
        break

# Liberar os recursos
cap.release()
cv2.destroyAllWindows()
```


## üéÅ Express√µes de gratid√£o

* Compartilhe com outras pessoas esse projeto üì¢;
* Quer saber mais sobre o projeto? Entre em contato para tomarmos um :coffee:;
