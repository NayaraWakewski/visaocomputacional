{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula de Visão Computacional"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos baixar um modelo pré treinado - Yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!curl -O https://pjreddie.com/media/files/yolov3.weights\n",
    "#!curl -O https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\n",
    "#!curl -O https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> yolov3.weights: https://pjreddie.com/media/files/yolov3.weights\n",
    "\n",
    "> yolov3.cfg: https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\n",
    "\n",
    "> coco.names: https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizaremos a biblioteca Cv2 que usa a câmera do notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install opencv -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Em caso de erro:\n",
    "#pip uninstall opencv-python\n",
    "#conda install -c conda-forge opencv=4.5.3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando DNN - Redes Neurais Profundas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os arquivos do modelo YOLO (os arquivos que nós baixamos)\n",
    "net = cv2.dnn.readNetFromDarknet('yolov3.cfg', 'yolov3.weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar as classes - e transformando em uma lista\n",
    "classes = []\n",
    "f = open('coco.names', 'r')\n",
    "lines = f.readlines()\n",
    "f.close()\n",
    "\n",
    "for line in lines:\n",
    "    classes.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar cores aleatórias para cada classe\n",
    "colors = np.random.uniform(0, 255, size=(len(classes), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar a imagem de exemplo\n",
    "image = cv2.imread('exemplo.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redimensionar a imagem se necessário\n",
    "# image = cv2.resize(image, None, fx=0.4, fy=0.4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando blob"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um \"blob\" é essencialmente uma matriz multidimensional que contém os valores de pixel normalizados da imagem, juntamente com informações adicionais, como dimensões, canais e outras configurações específicas da rede neural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter as dimensões da imagem\n",
    "height, width, _ = image.shape\n",
    "\n",
    "# Construir um blob a partir da imagem para o modelo YOLO\n",
    "blob = cv2.dnn.blobFromImage(image, 1/255, (416, 416), swapRB=True, crop=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir as camadas de saída\n",
    "#output_layers_names = net.getUnconnectedOutLayersNames()\n",
    "\n",
    "output_names = net.getUnconnectedOutLayersNames()\n",
    "output_layers = [net.getLayer(name) for name in output_names]\n",
    "output_layers = [layer.name for layer in output_layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passar o blob pela rede neural\n",
    "net.setInput(blob)\n",
    "outputs = net.forward(output_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar as listas de detecção\n",
    "class_ids = []\n",
    "confidences = []\n",
    "boxes = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste trecho de código, estamos analisando as saídas (outputs) da rede neural, que são as informações sobre os objetos detectados na imagem. Vamos percorrer cada uma dessas saídas para obter as informações de cada objeto detectado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processar as saídas da rede neural\n",
    "for output in outputs:\n",
    "    for detection in output:\n",
    "        scores = detection[5:]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "\n",
    "        if confidence > 0.5:\n",
    "            # Obter as coordenadas do objeto detectado\n",
    "            center_x = int(detection[0] * width)\n",
    "            center_y = int(detection[1] * height)\n",
    "            w = int(detection[2] * width)\n",
    "            h = int(detection[3] * height)\n",
    "\n",
    "            # Calcular os cantos do retângulo delimitador\n",
    "            x = int(center_x - w / 2)\n",
    "            y = int(center_y - h / 2)\n",
    "\n",
    "            # Adicionar as informações à lista de detecção\n",
    "            class_ids.append(class_id)\n",
    "            confidences.append(float(confidence))\n",
    "            boxes.append([x, y, w, h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar a supressão não máxima para eliminar detecções redundantes\n",
    "indices = cv2.dnn.NMSBoxes(boxes, confidences, score_threshold=0.5, nms_threshold=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desenhar os retângulos delimitadores e exibir as classes nas detecções\n",
    "for i in indices:\n",
    "    box = boxes[i]\n",
    "    x, y, w, h = box\n",
    "    label = f'{classes[class_ids[i]]}: {confidences[i]:.2f}'\n",
    "\n",
    "    color = colors[class_ids[i]]\n",
    "    cv2.rectangle(image, (x, y), (x+w, y+h), color, 2)\n",
    "    cv2.putText(image, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "# Exibir a imagem com as detecções\n",
    "cv2.imshow('Object Detection', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
